# -*- coding: utf-8 -*-
"""under_over.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w_1IzUqZVzFdvEMb-gfcfGaYD_iQLuzq

**Importar bibliotecas**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split

#from google.colab import drive

"""**Problema**

Vamos encontrar a curva da posição de uma bolinha que é solta a uma certa altura.

Então vamos gerar aleatoriamente as medidas de tempo, como se fossem pessoas cronometrando quantos segundos foram necessários para a bolinha atingir certa distância.
"""

t = np.arange(0,7,0.1) # eixo do tempo vai de 0 a 7 segundos
X = (0.9*9.8*t**2)/2.0 + 10*np.random.randn(t.shape[0])

plt.figure(figsize=(15,5))
plt.plot(t,X,'.')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlabel('tempo (s)', fontsize=15)
plt.ylabel('deslocamento (cm)', fontsize=15);

t.shape

X.shape

t=t.reshape(70,1)
X=X.reshape(70,1)

"""**Regressão linear**

Qual a melhor curva que descreve os pontos do gráfico acima?

Vamos treinar o modelo para descobrir!
"""

# normalizar
tn = StandardScaler().fit_transform(t)
Xn = StandardScaler().fit_transform(X)

lr = LinearRegression()
lr.fit(tn,Xn);

pred = lr.predict(tn)

plt.figure(figsize=(15,5))
plt.plot(tn,Xn,'.', label='gabarito')
plt.plot(tn,pred,'-', label='predicao')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlabel('tempo normalizado', fontsize=15)
plt.ylabel('deslocamento normalizado', fontsize=15)
plt.title('Underfitting', fontsize=15)
plt.legend();

"""A biblioteca LinearRegression aproxima os dados para uma reta.

Podemos ver que não é uma aproximação boa, pois a previsão erra muito para vários pontos.


**Polinômio de grau maior**

Vamos tentar encontrar um modelo que usa polinômio de grau maior que 1 para aproximar a curva.
"""

pf = PolynomialFeatures(degree=180,include_bias=False) # polinômio de grau 180

t_transformado = pf.fit_transform(t) # cria uma tabela com variável tempo elevada a cada uma das potências
T=pd.DataFrame(t_transformado)
T

"""**Treinar modelo**"""

t_transformado.shape

t_tn = StandardScaler().fit_transform(t_transformado)
lr = LinearRegression()
lr.fit(t_tn,Xn)

pred = lr.predict(t_tn)
pred

plt.figure(figsize=(15,5))
plt.plot(tn,Xn,'.', label='gabarito')
plt.plot(tn,pred,'-', label='predicao')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlabel('tempo normalizado', fontsize=15)
plt.ylabel('deslocamento normalizado', fontsize=15)
plt.title('Overfitting', fontsize=15)
plt.legend();

"""Agora o problema é que o modelo se ajustou bem demais aos pontos, até com ruído. Para qualquer outro conjunto de dados, a resposta será ruim."""

pf2 = PolynomialFeatures(degree=2,include_bias=False) 

t_transformado2 = pf2.fit_transform(t)
T2=pd.DataFrame(t_transformado2)
T2

t_tn2 = StandardScaler().fit_transform(t_transformado2)
lr = LinearRegression()
lr.fit(t_tn2,Xn)

pred = lr.predict(t_tn2)
pred

plt.figure(figsize=(15,5))
plt.plot(tn,Xn,'.', label='gabarito')
plt.plot(tn,pred,'-', label='predicao')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlabel('tempo normalizado', fontsize=15)
plt.ylabel('deslocamento normalizado', fontsize=15)
plt.title('Polinômio de grau 2', fontsize=15)
plt.legend();

"""Em problemas da vida real, dificilmente saberemos o grau do polinômio que precisamos usar. Como contornar esse problema?"""

t_train, t_test, X_train, X_test = train_test_split(t,X,test_size=0.3)

graus = range(1,100)
erros = []

for n_pol in graus:
  pf = PolynomialFeatures(degree=n_pol, include_bias=False)

  Xn_train = StandardScaler().fit_transform(X_train)
  Xn_test = StandardScaler().fit_transform(X_test)

  t_train_transformado = pf.fit_transform(t_train)
  t_train_tn = StandardScaler().fit_transform(t_train_transformado) # normalizar

  t_test_transformado = pf.transform(t_test)
  t_test_tn = StandardScaler().fit_transform(t_test_transformado) # normalizar

  lr = LinearRegression()
  lr.fit(t_train_tn, Xn_train)

  pred = lr.predict(t_test_tn)

  erros.append(np.mean(np.abs(pred - Xn_test)))

plt.figure(figsize=(15,5))
plt.plot(graus, erros, '.-')
plt.title('Erros para graus de 1 a 100')

plt.figure(figsize=(15,5))
plt.plot(graus[0:40], erros[0:40], '.-')
plt.title('Erros para graus de 1 a 40')

plt.figure(figsize=(15,5))
plt.plot(graus[0:15], erros[0:15], '.-')
plt.title('Erros para graus de 1 a 15')

plt.figure(figsize=(15,5))
plt.plot(graus[0:4], erros[0:4], '.-')
plt.title('Erros para graus de 1 a 4');

"""O polinômio que mostrou menos erros foi o de grau 2."""

n_pol=2
pf = PolynomialFeatures(degree=n_pol, include_bias=False)

Xn_train = StandardScaler().fit_transform(X_train)
Xn_test = StandardScaler().fit_transform(X_test)

t_train_transformado = pf.fit_transform(t_train)
t_train_tn = StandardScaler().fit_transform(t_train_transformado) # normalizar

t_test_transformado = pf.transform(t_test)
t_test_tn = StandardScaler().fit_transform(t_test_transformado) # normalizar

lr = LinearRegression()
lr.fit(t_train_tn, Xn_train)

pred = lr.predict(t_test_tn)

tn = StandardScaler().fit_transform(t_test)
plt.figure(figsize=(15,5))
plt.plot(tn,Xn_test,'.', label='gabarito')
plt.plot(tn,pred,'.', label='predicao')
#plt.plot(t_train_tn,Xn_train,'.', label='gabarito')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlabel('tempo normalizado', fontsize=15)
plt.ylabel('deslocamento normalizado', fontsize=15)
plt.title('Polinômio de grau 2 aplicado ao conjunto de teste', fontsize=15)
plt.legend();